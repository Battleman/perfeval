{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(df['Start'], range(len(df)), label=\"Arrived\")\n",
    "plt.step(df['T22'], range(len(df)),label=\"Served\")\n",
    "plt.title(\"Number of requests arrived and served\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.step(df['Start'][100:150], range(50), label=\"Arrived\")\n",
    "plt.step(df['T22'][100:150], range(50), label=\"Served\")\n",
    "plt.title(\"Number of requests arrived and served (zoomed)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average response time (event average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time difference between end of task, and beginning of task\n",
    "# for each type of task\n",
    "df['T1-Serv'] = df['T12']-df['Start'] # serv time for type 1\n",
    "df['T2-Serv'] = df['T22']-df['T12']  # serv time for type2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([1],[df['T1-Serv'].mean()], label=\"Type 1\")\n",
    "plt.bar([2],[df['T2-Serv'].mean()], label=\"Type 2\")\n",
    "plt.title(\"Average response time for a job\")\n",
    "plt.xticks([])\n",
    "plt.ylabel('Miliseconds')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average number of jobs served per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "served = []\n",
    "for sample_start_time in (df.values.max()-1000)*np.random.sample(100):\n",
    "    served.append(df[(df['T21'] > sample_start_time) & (df['T22'] < sample_start_time+1000)].count()['Start'])\n",
    "print(\"Average number of Type 1 jobs served per second: {}\".format(np.mean(served)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "served = []\n",
    "for sample_start_time in (df.values.max()-1000)*np.random.sample(50):\n",
    "    served.append(df[(df['T11'] > sample_start_time) & (df['T12'] < sample_start_time+1000)].count()['Start'])\n",
    "print(\"Average number of Type 2 jobs served per second: {}\".format(np.mean(served)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the number of jobs served per second is in both cases close to 80, as the server can keep up with the requests rate, of 80 requests/seconds. So the queue being most of the time almose empty, the rate is obviously close to 80."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.arange(25, 250, 25)\n",
    "queues = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "#for l in lambdas: \n",
    "#    it = compute(l)\n",
    "#    items.append(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(items)): \n",
    "#    df = pd.DataFrame(items[i], columns = ['Start', 'T11', 'T12', 'T21', 'T22'])\n",
    "#    df.to_csv(\"lambda_\"+str(25*(i+1)), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Remove Transients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With transient present\n",
    "### $\\lambda = 60$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_type_i_in_queue, plot_type_i_in_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df60 = compute(60)\n",
    "interesting_times60, type1_in_queue_60, type2_in_queue_60 = get_type_i_in_queue(df60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_type_i_in_queue(interesting_times60, type1_in_queue_60, type2_in_queue_60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CI for median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import ci_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,h = ci_median(len(interesting_times60))\n",
    "a = np.sort(type1_in_queue_60)\n",
    "b = np.sort(type2_in_queue_60)\n",
    "print(\"The CI for median with lambda=60 are, at 95% confidence, between\\n\\ttype1: {} and {}\\n\\ttype2: {} and {}\".format(a[l], a[h], b[l], b[h]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CI for mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import ci_mean_large_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_means_type1 = ci_mean_large_n(type1_in_queue_60)\n",
    "ci_means_type2 = ci_mean_large_n(type2_in_queue_60)\n",
    "print(\"The CI for median with lambda=60 are, at 95% confidence,\\\n",
    "between\\n\\ttype1: {:.3f} and {:.3f}\\n\\\n",
    "\\ttype2: {:.3f} and {:.3f}\".format(ci_means_type1[0], ci_means_type1[1], \n",
    "                                   ci_means_type2[0], ci_means_type2[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\lambda = 160$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CI for median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df160 = compute(160)\n",
    "interesting_times160, type1_in_queue_160, type2_in_queue_160 = get_type_i_in_queue(df160)\n",
    "plot_type_i_in_queue(interesting_times160, type1_in_queue_160, type2_in_queue_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,h = ci_median(len(interesting_times60))\n",
    "type1_160_sorted = np.sort(type1_in_queue_160)\n",
    "type2_160_sorted = np.sort(type2_in_queue_160)\n",
    "print(\"The CI for median with lambda=60 are, at 95% confidence,\\\n",
    "between\\n\\ttype1: {} and {}\\\n",
    "\\n\\ttype2: {} and {}\".format(type1_160_sorted[l], type1_160_sorted[h], \n",
    "                             type2_160_sorted[l], type2_160_sorted[h]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CI for mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_means_type1 = ci_mean_large_n(type1_in_queue_160)\n",
    "ci_means_type2 = ci_mean_large_n(type2_in_queue_160)\n",
    "print(\"The CI for median with lambda=160 are, at 95% confidence,\\\n",
    "between\\n\\ttype1: {:.3f} and {:.3f}\\n\\\n",
    "\\ttype2: {:.3f} and {:.3f}\".format(ci_means_type1[0], ci_means_type1[1], \n",
    "                                   ci_means_type2[0], ci_means_type2[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the transient removed\n",
    "For $\\lambda = 60$, the analysis is the same as before, as there seems to be no transient. Indeed, the buffer is most of the time empty or nearly empty, steadily accross time. Thus we do not repeat the calculation.\n",
    "\n",
    "For $\\lambda = 160$, we use as transient period the time until the buffer size reaches the mean of both objects (that is 97.884). Everything before this threshold is reached is considered transient period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing moment the threshold is first crossed\n",
    "buffer_size = np.array(type1_in_queue_160 + type2_in_queue_160)\n",
    "threshold = np.mean(buffer_size)\n",
    "threshold_crossing = np.argwhere(buffer_size > threshold)[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CI for median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing median on reduced array\n",
    "med_l_ind, med_h_ind = ci_median(len(interesting_times160[threshold_crossing:]))\n",
    "#lower and higher for type 1\n",
    "med_l_type1 = type1_160_sorted[threshold_crossing+med_l_ind]\n",
    "med_h_type1 = type1_160_sorted[threshold_crossing+med_h_ind]\n",
    "\n",
    "med_l_type2 = type2_160_sorted[threshold_crossing+med_l_ind]\n",
    "med_h_type2 = type2_160_sorted[threshold_crossing+med_h_ind]\n",
    "print(\"CI for median, lambda=160, no transient, at 95% level:\\n\\\n",
    "\\tType1: {} - {}\\n\\\n",
    "\\tType2: {} - {}\".format(med_l_type1, med_h_type1, \n",
    "                         med_l_type2, med_h_type2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CI for mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_mean_l_type1, ci_mean_h_type1 = ci_mean_large_n(type1_in_queue_160[threshold_crossing:])\n",
    "ci_mean_l_type2, ci_mean_h_type2 = ci_mean_large_n(type2_in_queue_160[threshold_crossing:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CI for mean, lambda=160, no transient, at 95% level:\\n\\\n",
    "\\tType1: {:.3f} - {:.3f}\\n\\\n",
    "\\tType2: {:.3f} - {:.3f}\".format(ci_mean_l_type1, ci_mean_h_type1, \n",
    "                         ci_mean_l_type2, ci_mean_h_type2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PerfEval",
   "language": "python",
   "name": "perfeval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
